<!DOCTYPE html>
<html prefix="
og: http://ogp.me/ns#
article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width">
<title>Understanding Allen Downey's Solution to the M&amp;M Problem | Broca's Brain</title>
<link href="../../assets/css/bitter.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/main.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://jaidevd.github.io/posts/understanding-allen-downeys-solution-to-the-mm-problem/">
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script><!--[if lt IE 9]><script src="/assets/js/html5.js"></script><![endif]--><meta name="author" content="Jaidev Deshpande">
<meta property="og:site_name" content="Broca's Brain">
<meta property="og:title" content="Understanding Allen Downey's Solution to the M&amp;M Problem">
<meta property="og:url" content="https://jaidevd.github.io/posts/understanding-allen-downeys-solution-to-the-mm-problem/">
<meta property="og:description" content='Allen Downey makes a very good case for learning advanced mathematics through
programming (Check the first section of the preface of Think Bayes, titled "My theory, which is mine").
But before the rea'>
<meta property="og:type" content="article">
<meta property="article:published_time" content="2016-06-30T18:33:41+05:30">
<meta property="article:tag" content="bayes">
<meta property="article:tag" content="learning">
<meta property="article:tag" content="math">
<meta property="article:tag" content="programming">
</head>
<body>
    <section class="social"><ul>
<li><a href="../../index.html" title="Home"><i class="icon-home"></i></a></li>
            <li><a href="https://twitter.com/jaidevd" title="My Twitter"><i class="icon-twitter"></i></a></li>
            <li><a href="https://github.com/jaidevd" title="My Github"><i class="icon-github"></i></a></li>
            <li><a href="../../archive.html" title="Archives"><i class="icon-folder-open-alt"></i></a></li>
            <li><a href="../../categories/index.html" title="Tags"><i class="icon-tags"></i></a></li>
            <li><a href="../../rss.xml" title="RSS"><i class="icon-rss"></i></a></li>
            <li><a href="https://www.goodreads.com/review/list/8656004" title="Reading List"><i class="icon-book"></i></a></li>

        </ul></section><section class="page-content"><div class="content" rel="main">
    <div class="post">
        <h1 class="p-name entry-title" itemprop="headline name">Understanding Allen Downey's Solution to the M&amp;M Problem</h1>

        <div class="meta">
            <div class="authordate">
                <time class="timeago" datetime="2016-06-30T18:33:41+05:30">30 Jun 2016 18:33</time>
            
                      |  
        <a href="index.ipynb" id="sourcelink">Source</a>
          |  
        <a href="javascript:%24.getScript(%22/assets/js/miniPageNav.js%22);">Minimap</a>

            </div>
                    <div itemprop="keywords" class="tags">
        <ul>
        Tags : 
           <li><a class="tag p-category" href="../../categories/bayes/" rel="tag">bayes</a></li>
           <li><a class="tag p-category" href="../../categories/learning/" rel="tag">learning</a></li>
           <li><a class="tag p-category" href="../../categories/math/" rel="tag">math</a></li>
           <li><a class="tag p-category" href="../../categories/programming/" rel="tag">programming</a></li>
        </ul>
</div>

        </div>
        <div class="body">
            <div class="cell border-box-sizing text_cell rendered">
<div class="prompt input_prompt">
</div>
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<!-- 
.. title: Understanding Allen Downey's Solution to the M&M Problem
.. slug: understanding-allen-downeys-solution-to-the-mm-problem
.. date: 2016-06-29 20:13:56 UTC+05:30
.. tags: learning, bayes, programming, math, mathjax
.. category: 
.. link: 
.. description: 
.. type: text
-->

<p>Allen Downey makes a very good case for learning advanced mathematics through
programming (Check the first section of the preface of <em>Think Bayes</em>, titled "My theory, which is mine").
But before the reader can hit paydirt with using the Bayes theorem in programming,
Downey makes you go through some elementary problems in probability, which have
to be solved by hand first, if you expect to have a clear enough understanding
of the concept. I can vouch for this way of learning complex concepts. The way
I learnt the backpropagation algorithm (and its derivation), was with a pen,
paper and a calculator.
<!-- TEASER_END --></p>
<p>Downey is also very careful about pointing out the difference between how
functions and operations manifest themselves in math and in programming. For
example, a function (say, $f(x)$) in mathematics can be implemented in software
by a number of things:</p>
<ul>
<li>An array, containing only data</li>
<li>A routine that takes input(s) ($x$) and provides an output(s) ($f(x)$)</li>
<li>A symbolic expression (commonly found in <a href="https://en.wikipedia.org/wiki/Computer_algebra_system">CAS</a> libraries)</li>
</ul>
<p>Not knowing these differences can severly handicap a programmer. I, for one,
found myself stymied multiple times in the very first chapter of <em>Think Bayes</em>,
even though I'm quite comfortable with what the Bayes theorem represents and
what it means for problems where belief or confidence needs to keep changing
with data. But here's the rub: I'm used to thinking about it very formally, in terms of
continuous functions, not discrete structures. And that has been the downfall
of many a programmer.</p>
<p>What follows is just narcissistic note-taking, which I hope won't let me forget
what I've already learnt.</p>
<h3 id="Bayes'-Theorem">Bayes' Theorem<a class="anchor-link" href="#Bayes'-Theorem">¶</a>
</h3>
<p>Simply put, it says that given data $D$ and a hypothesis $H$</p>
$$ \begin{equation} P(H|D) = \frac{P(H)P(D|H)}{P(D)} \end{equation} $$<p>where
$P(H)$ is the probability of the hypothesis, or the <em>prior</em>. $P(D|H)$ is the
<em>likelihood</em>, the probability that a favourable outcome (or anything that is
being observed) is true under the hypothesis $H$. $P(D)$ is the normalizing
constant, or the probability of the data being true in any case at all. The
significance of the normalizing constant is not immediately apparent, but we
can think of it as follows:</p>
<blockquote>
<p>If there are multiple possibilities, or multiple hypothesis, then $P(D)$ is
the probability of an observation being true under any of them.</p>
</blockquote>
<p>Concretely, this means that if there are $n$ hypotheses $H_{1}$ through
$H_{n}$, then</p>
$$ P(D) = \sum_{i=1}^{n} P(H_{i}) P(D|H_{i}) $$<h3 id="The-M&amp;M-Problem">The M&amp;M Problem<a class="anchor-link" href="#The-M&amp;M-Problem">¶</a>
</h3>
<p>The problem states that the distribution of colors among M&amp;Ms before and after
1995 is as follows:</p>
<table>
<thead><tr style="text-align: right;">
<th>Color</th>
      <th>Before 1995</th>
      <th>After 1995</th>
     </tr></thead>
<tbody>
<tr>
<td>brown</td>
      <td>30 %</td>
      <td>13 %</td>
    </tr>
<tr>
<td>yellow</td>
      <td>20 %</td>
      <td>14 %</td>
    </tr>
<tr>
<td>red</td>
      <td>20 %</td>
      <td>13 %</td>
    </tr>
<tr>
<td>green</td>
      <td>10 %</td>
      <td>20 %</td>
    </tr>
<tr>
<td>orange</td>
      <td>10 %</td>
      <td>16 %</td>
    </tr>
<tr>
<td>tan</td>
      <td>10 %</td>
      <td>0 %</td>
    </tr>
<tr>
<td>blue</td>
      <td>0 %</td>
      <td>24 %</td>
    </tr>
</tbody>
</table>
<p>We have two bags full of M&amp;Ms, one from 1994 and the other from 1996. We draw
an M&amp;M each from the two bags, without knowing which M&amp;M came from which bag.
One is yellow and one is green. The problem is:</p>
<blockquote>
<p>What is the probability that the yellow M&amp;M came from the 1994 bag?</p>
</blockquote>
<p>There can only be two hypotheses here:</p>
<ul>
<li>Hypothesis A ($H_{a}$): The yellow M&amp;M came from the 1994 bag, and the green one came from the 1996 bag.</li>
<li>Hypothesis B ($H_{b}$): The yellow M&amp;M came from the 1996 bag, and the green one came from the 1994 bag.</li>
</ul>
<p>Downey also introduces a useful notation for solving such problems, where we arrange the hypotheses and their corresponding Bayesian parameters in a table as follows:</p>
<table>
<thead><tr style="text-align: right;">
<th></th>
      <th>Prior</th>
      <th>Likelihood</th>
      <th>Normalizing Constant</th>
    </tr></thead>
<tbody>
<tr>
<th>A</th>
      <td>?</td>
      <td>?</td>
      <td>?</td>
    </tr>
<tr>
<th>B</th>
      <td>?</td>
      <td>?</td>
      <td>?</td>
    </tr>
</tbody>
</table>
<p>As we proceed with this problem, we'll also see how it serves as a good example of the diachronic interpretation of the Bayes' theorem - i.e., how it helps us update our belief about a given hypothesis once we've seen more data.</p>
<ol>
<li>Our <em>priors</em> about the two hypotheses would be naive, in that we would expect both hypotheses to be equiprobable, since we haven't considered the color distribution yet. Thus, $ P(H_{a}) = P(H_{b}) = \frac{1}{2}$</li>
<li>The likelihoods for the respective hypotheses can be readily obtained from the color distribution. Recall that $P(D|H_{a})$ is simply the probability that the observed data (one green, one yellow) is true for hypothesis $H_{a}$. Thus, $P(D|H_{a})$ equals the probability that the yellow M&amp;M is from 1994 <em>and</em> the green one is from 1996. From the table, these values are both $\frac{1}{5}$. Thus, $P(D|H_{a}) = \frac{1}{25}$. Similarly, $P(D|H_{b}) = \frac{14}{100} \times \frac{10}{100} = \frac{7}{500}$.</li>
<li>Note that for each hypothesis, the product of the first two columns makes up the numerator of the right hand side of Bayes' equation.</li>
</ol>
<p>So far so good, but I was stuck for a while before I could understand Downey's explanation of how he calculated the normalizing constant for the two cases. He writes that the third column is just the sum of the products of the first two columns. This means, that the normalizing constant is just the sum of the numerators for the respective Bayes' equations for the two scenarios. So,</p>
$$ P(D) = P(H_{a})P(D|H_{a}) + P(H_{b})P(D|H_{b})$$<p>Thus,</p>
$$ P(D) = \frac{1}{2} \times \frac{1}{25} + \frac{1}{2} \times \frac{7}{500} = \frac{27}{1000} $$<p>The catch is that this equation is perfectly in line with the second equation, subject to the assumption that both hypothesis are mutually exclusive (only one can be true) and collectively exhaustive (at least one must be true).</p>
<p>Since we now know all the values required to calculate the posteriors of both hypothesis, the rest is just arithmetic. It turns out that $P(H_{a}|D) = \frac{20}{27}$ and $P(H_{b}|D) = \frac{7}{27}$.</p>
<p>This was so much fun on paper, I can't wait to use these methods in Python. Needless to say I'm pretty excited about working through <em>Think Bayes</em>.</p>

</div>
</div>
</div>
        </div>
                <ul class="pager hidden-print">
<li class="previous">
                <a href="../a-short-rant-about-foss-communities/" rel="prev" title="Evangelism in FOSS">Previous post</a>
            </li>
            <li class="next">
                <a href="../a-geometric-proof-of-the-perceptron-convergence-theorem/" rel="next" title="A Geometric Proof of the Perceptron Convergence Theorem">Next post</a>
            </li>
        </ul>
<div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="brocasbrain",
            disqus_url="https://jaidevd.github.io/posts/understanding-allen-downeys-solution-to-the-mm-problem/",
        disqus_title="Understanding Allen Downey's Solution to the M&M Problem",
        disqus_identifier="cache/posts/understanding-allen-downeys-solution-to-the-mm-problem.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


                            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha256-SDRP1VVYu+tgAGKhddBSl5+ezofHKZeI+OzxakbIe/Y=" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
    },
    displayAlign: 'left', // Change this to 'center' to center equations.
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}}
    }
});
</script>
</div>
                    <footer id="footer"><p>Contents © 2018         <a href="mailto:deshpande.jaidev@gmail.com">Jaidev Deshpande</a> - Powered by         <a href="https://getnikola.com" rel="nofollow">Nikola</a>         </p>
            
        </footer>
</div>
    </section><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-80129098-1', 'auto');
  ga('send', 'pageview');

</script><script src="../../assets/js/jquery-1.10.2.min.js" type="text/javascript"></script><script src="../../assets/js/jquery.timeago.js" type="text/javascript"></script><!-- Social buttons --><div id="addthisbox" class="addthis_toolbox addthis_peekaboo_style addthis_default_style addthis_label_style addthis_32x32_style">
<a class="addthis_button_more">Share</a>
<ul>
<li>
<a class="addthis_button_twitter"></a>
</li>
<li>
<a class="addthis_button_facebook"></a>
</li>
<li>
<a class="addthis_button_google_plusone_share"></a>
</li>
<li>
<a class="addthis_button_linkedin"></a>
</li>
</ul>
</div>
<script src="https://s7.addthis.com/js/300/addthis_widget.js#pubid=ra-4f7088a56bb93798"></script><!-- End of social buttons --><script type="text/javascript">
            $(function(){
                $('.timeago').timeago();
            });
        </script>
</body>
</html>
